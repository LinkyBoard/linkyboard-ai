# 🎯 Clipper 태그/카테고리 추출 비용 절감 계획

## 📊 현재 상황

### 기존 시스템
- OpenAI API 사용 (gpt-4o-mini)
- 매 웹페이지마다 2회 API 호출 (태그 + 카테고리)
- HTML 파싱 없이 raw content 사용
- 월 예상 비용: 높음 (사용량에 따라 급증)

### 문제점
1. **높은 API 비용**: 매번 OpenAI 호출
2. **비효율적인 HTML 처리**: 불필요한 태그/스크립트까지 처리
3. **확장성 제한**: 사용량 증가 시 비용 급증

## 🚀 새로운 시스템 설계

### 1. HTML 파싱 최적화
```
Raw HTML → trafilatura → 핵심 텍스트 추출 → 키워드 추출
```

### 2. 로컬 NLP 기반 키워드 추출
```
핵심 텍스트 → spaCy(한국어) + TF-IDF → 명사 키워드 리스트
```

### 3. 사용자 히스토리 기반 추천
```
추출 키워드 + 사용자 기존 태그/카테고리 → 유사도 계산 → 최적 추천
```

### 4. 하이브리드 접근법
- **1차**: 로컬 알고리즘으로 기본 추출
- **2차**: 사용자 히스토리 매칭
- **3차**: 필요시에만 경량 LLM 사용 (fallback)

## 🔧 구현 계획

### Phase 1: HTML 파싱 개선
- trafilatura 라이브러리 도입
- 핵심 콘텐츠 추출 로직 구현

### Phase 2: 로컬 NLP 시스템
- spaCy 한국어 모델 설치
- TF-IDF 기반 키워드 추출
- 명사 필터링 및 정제

### Phase 3: 사용자 히스토리 활용
- 기존 태그/카테고리 빈도 분석
- 유사도 기반 추천 시스템
- 학습 데이터 축적

### Phase 4: 성능 최적화
- 캐싱 시스템 도입
- 배치 처리 최적화
- 메모리 효율성 개선

## 📈 예상 효과

### 비용 절감
- OpenAI API 호출 **90% 감소**
- 월 운영비용 **80% 절약**

### 성능 개선
- 응답 시간 **50% 단축** (네트워크 대기 제거)
- 안정성 향상 (외부 API 의존성 감소)

### 확장성
- 사용량 증가에도 비용 선형 증가 방지
- 오프라인 처리 가능

## 🎯 성공 지표

1. **비용**: OpenAI API 호출 90% 감소
2. **정확도**: 기존 대비 80% 이상 유지
3. **속도**: 응답 시간 50% 단축
4. **만족도**: 사용자 태그 재사용률 증가